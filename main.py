import streamlit as st
from openai import OpenAI
import os
from dotenv import load_dotenv
from PIL import Image
import requests
from io import BytesIO
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import pandas as pd

try:
    import cv2
except ImportError as e:
    st.error(f"OpenCV import failed: {e}")
    st.info("Please install opencv-python-headless for deployment environments")
    st.stop()
import numpy as np
from datetime import datetime


# ğŸ” OpenAI API í‚¤

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)


def get_features(image: Image.Image):
    img = np.array(image)
    img = cv2.resize(img, (512, 512))
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 1. Sobel í•„í„°ë¡œ ì—£ì§€(êµ¬ì¡°) ì¶”ì¶œ
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    edge = np.sqrt(sobelx**2 + sobely**2)

    # 2. ìƒ‰ìƒ íŠ¹ì§• ì¶”ì¶œ (RGB í‰ê· )
    mean_color = img.mean(axis=(0, 1))  # shape (3,)

    # 3. ë²¡í„°ë¡œ ê²°í•© (flattenëœ edge + ìƒ‰ìƒ í‰ê· )
    edge_vec = cv2.resize(edge, (32, 32)).flatten()  # ì¤„ì—¬ì„œ ë²¡í„°í™”
    edge_vec = edge_vec / np.linalg.norm(edge_vec)  # ì •ê·œí™”
    color_vec = mean_color / 255
    feature_vec = np.concatenate([edge_vec, color_vec])

    return feature_vec


def compute_similarity(
    created_image_tensor: torch.Tensor,
    target_image_tensor: torch.Tensor,
):
    model = models.vgg16(pretrained=True)
    model.eval()
    with torch.no_grad():
        created_image_feature = model(created_image_tensor)
        target_image_feature = model(target_image_tensor)
    return float(
        (created_image_feature @ target_image_feature.T).item()
        / (np.linalg.norm(created_image_feature) * np.linalg.norm(target_image_feature))
    )


def update_leaderboard(name, score, file_name):
    file = "leaderboard.csv"
    df = (
        pd.read_csv(file)
        if os.path.exists(file)
        else pd.DataFrame(columns=["ì´ë¦„", "ì ìˆ˜", "ì‚¬ì§„"])
    )
    df.loc[len(df)] = [name, round(score, 4), file_name]
    df.to_csv(file, index=False)
    return df


def generate_image_from_openai(username, prompt):
    response = client.images.generate(
        model="dall-e-2",
        prompt=prompt,
        n=1,
        size="512x512",
    )
    image_url = response.data[0].url
    created = response.created
    image = Image.open(BytesIO(requests.get(image_url).content))
    # í˜„ì¬ ì‹œê°„ê³¼ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    current_time = datetime.now()
    # ì›”-ì¼-ì‹œê°„-ë¶„ í˜•íƒœë¡œ í¬ë§·íŒ…
    formatted_time = current_time.strftime("%m-%d-%H-%M")

    # generated_images í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs("generated_images", exist_ok=True)
    file_name = f"{username}_{formatted_time}_{created}"
    image.save(f"generated_images/{file_name}")
    return image, file_name


# 1. Define the model
class PretrainedResNetFeatureExtractor(nn.Module):
    def __init__(self, output_dim=128, pretrained=True):
        super().__init__()
        base_model = models.resnet18(pretrained=pretrained)
        self.backbone = nn.Sequential(
            *list(base_model.children())[:-1]
        )  # remove avgpool + fc
        self.projector = nn.Linear(512, output_dim)

    def forward(self, x):
        x = self.backbone(x)  # [B, 512, 1, 1]
        x = x.view(x.size(0), -1)  # [B, 512]
        x = self.projector(x)  # [B, output_dim]
        return x


# 2. Define the image transform (resize + ToTensor only, no normalization)
transform = transforms.Compose(
    [
        transforms.Resize((512, 512)),
        transforms.ToTensor(),  # scales to [0, 1]
    ]
)


# 3. Load image (PIL.Image)
def load_image(image: Image.Image):
    img = image.convert("RGB")
    return transform(img).unsqueeze(0)  # add batch dimension â†’ [1, 3, 512, 512]


# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if "selected_leaderboard_image" not in st.session_state:
    st.session_state.selected_leaderboard_image = None

# ğŸŒ Streamlit UI
st.title("ì´ë¯¸ì§€ í”„ë¡¬í”„íŒ… ì±Œë¦°ì§€")
st.subheader("ì£¼ì–´ì§„ ì‚¬ì§„ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ì§„ì„ ë§Œë“œì‹ ë¶„ì—ê²Œ ì†Œì •ì˜ ìƒí’ˆì„ ë“œë¦½ë‹ˆë‹¤.")
st.info("ê¸°í•œ : 2025ë…„ 6ì›” 13ì¼ 18ì‹œ 00ë¶„")
st.image("images/target_image.png", caption="ëª©í‘œ ì‚¬ì§„", use_container_width=True)

name = st.text_input("ğŸ‘¤ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”(í•™ë²ˆê³¼ ì´ë¦„)")
prompt = st.text_area("ğŸ’¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")


@st.dialog("ì´ë¯¸ì§€ ë³´ê¸°")
def show_image(image, score):
    try:
        st.image(f"generated_images/{image}.png", caption=f"ìœ ì‚¬ë„ : {score}")
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {e}")
    if st.button("í™•ì¸", type="primary"):
        st.session_state.selected_leaderboard_image = None
        st.rerun()


if st.session_state.selected_leaderboard_image:
    show_image(
        st.session_state.selected_leaderboard_image["url"],
        st.session_state.selected_leaderboard_image["score"],
    )

with st.sidebar:
    st.subheader("ğŸ† ë¦¬ë”ë³´ë“œ (Top 10)")

    # ë¦¬ë”ë³´ë“œ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists("leaderboard.csv"):
        df = pd.read_csv("leaderboard.csv")
        df = df.sort_values("ì ìˆ˜", ascending=False).reset_index(drop=True)[:10]

        if not df.empty:
            for idx, row in df.iterrows():
                rank = idx + 1
                col1, col2 = st.columns([3, 1])

                with col1:
                    st.write(f"**{rank}ìœ„** {row['ì´ë¦„']}")
                    st.write(f"ì ìˆ˜: {row['ì ìˆ˜']}")

                with col2:
                    if st.button("ì‚¬ì§„ë³´ê¸°", key=f"view_{row['ì‚¬ì§„']}"):
                        st.session_state.selected_leaderboard_image = {
                            "name": row["ì´ë¦„"],
                            "score": row["ì ìˆ˜"],
                            "url": row["ì‚¬ì§„"],
                        }
                        st.rerun()

                st.markdown("---")
        else:
            st.info("ì•„ì§ ì°¸ì—¬ìê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì•„ì§ ì°¸ì—¬ìê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ ë¦¬ë”ë³´ë“œê°€ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.")


if st.button("ì´ë¯¸ì§€ ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚°"):
    if not name or not prompt:
        st.warning("ì´ë¦„ê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
            try:
                generated_img, file_name = generate_image_from_openai(name, prompt)
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                st.stop()

        st.image(generated_img, caption="ğŸ–¼ï¸ ìƒì„±ëœ ì´ë¯¸ì§€", use_container_width=True)

        with st.spinner("ìœ ì‚¬ë„ ê³„ì‚° ì¤‘..."):
            scores = 0.0
            generated_img_tensor = load_image(generated_img)
            target_img_tensor = load_image(Image.open("images/target_image.png"))
            scores = compute_similarity(generated_img_tensor, target_img_tensor)
            st.success(f"ìœ ì‚¬ë„ ì ìˆ˜: {scores:.4f}")

        df = update_leaderboard(name, scores, file_name)
